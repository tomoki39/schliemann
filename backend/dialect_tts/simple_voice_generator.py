#!/usr/bin/env python3
"""
ã‚·ãƒ³ãƒ—ãƒ«éŸ³å£°ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ 
ç¢ºå®Ÿã«å‹•ä½œã™ã‚‹éŸ³å£°ç”Ÿæˆã‚’æä¾›
"""

import os
import numpy as np
import soundfile as sf
import librosa
import logging
from typing import Dict, Any
import asyncio
import subprocess
import tempfile

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SimpleVoiceGenerator:
    """ã‚·ãƒ³ãƒ—ãƒ«éŸ³å£°ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.sample_rate = 22050
        
        # ä¸Šæµ·èªèªå½™ãƒãƒƒãƒ—
        self.vocabulary_map = {
            "ä½ å¥½": "ä¾¬å¥½", "ä»Šå¤©": "ä»Šæœ", "å¾ˆå¥½": "è›®å¥½", "æˆ‘ä»¬": "é˜¿æ‹‰",
            "ä»€ä¹ˆ": "å•¥", "æ€ä¹ˆ": "å“ªèƒ½", "å“ªé‡Œ": "å•¥åœ°æ–¹", "è°¢è°¢": "è°¢è°¢ä¾¬",
            "å†è§": "å†ä¼š", "å¯¹ä¸èµ·": "å¯¹å‹¿èµ·", "æ²¡å…³ç³»": "å‘’æ²¡å…³ç³»",
            "å®¶": "å±‹é‡Œ", "å­¦æ ¡": "å­¦å ‚", "å·¥ä½œ": "åšç”Ÿæ´»", "å­¦ä¹ ": "è¯»ä¹¦",
            "åƒ": "åƒ", "å–": "åƒ", "èµ°": "è·‘", "å": "å", "ç«™": "ç«‹",
            "ç¡": "å›°è§‰", "çœ‹": "çœ‹", "å¬": "å¬", "è¯´": "è®²", "æƒ³": "æƒ³",
            "æ˜¯": "æ˜¯", "ä¸æ˜¯": "å‹¿æ˜¯", "æœ‰": "æœ‰", "æ²¡æœ‰": "å‘’æ²¡",
            "å¯ä»¥": "å¯ä»¥", "ä¸å¯ä»¥": "å‹¿å¯ä»¥", "è¦": "è¦", "ä¸è¦": "å‹¿è¦",
            "ä¼š": "ä¼š", "ä¸ä¼š": "å‹¿ä¼š", "èƒ½": "èƒ½", "ä¸èƒ½": "å‹¿èƒ½",
            "ä¸€": "ä¸€", "äºŒ": "ä¸¤", "ä¸‰": "ä¸‰", "å››": "å››", "äº”": "äº”",
            "å…­": "å…­", "ä¸ƒ": "ä¸ƒ", "å…«": "å…«", "ä¹": "ä¹", "å": "å",
        }
    
    def convert_text_to_shanghai(self, text: str) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸Šæµ·èªã«å¤‰æ›"""
        converted_text = text
        
        # èªå½™å¤‰æ›
        for standard, shanghai in self.vocabulary_map.items():
            converted_text = converted_text.replace(standard, shanghai)
        
        return converted_text
    
    async def generate_voice(self, text: str) -> np.ndarray:
        """éŸ³å£°ã‚’ç”Ÿæˆ"""
        logger.info(f"ğŸ—£ï¸ éŸ³å£°ç”Ÿæˆé–‹å§‹: {text}")
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸Šæµ·èªã«å¤‰æ›
        shanghai_text = self.convert_text_to_shanghai(text)
        logger.info(f"èªå½™å¤‰æ›: {text} â†’ {shanghai_text}")
        
        # è¤‡æ•°ã®æ–¹æ³•ã§éŸ³å£°ç”Ÿæˆã‚’è©¦è¡Œï¼ˆç¢ºå®ŸãªéŸ³å£°ã‚’å„ªå…ˆï¼‰
        methods = [
            self._generate_with_python_tts,       # Python TTSï¼ˆæœ€å„ªå…ˆï¼‰
            self._generate_with_say,              # macOS say
            self._generate_with_espeak,           # espeak
            self._generate_with_basic_synthesis,  # æœ€å¾Œã«åŸºæœ¬åˆæˆ
        ]
        
        for method in methods:
            try:
                audio = await method(shanghai_text)
                if audio is not None and len(audio) > 0:
                    logger.info(f"âœ… éŸ³å£°ç”ŸæˆæˆåŠŸ: {method.__name__} ({len(audio)} samples, {len(audio)/self.sample_rate:.2f}s)")
                    return audio
            except Exception as e:
                logger.warning(f"âš ï¸ {method.__name__} å¤±æ•—: {e}")
                continue
        
        # ã™ã¹ã¦ã®æ–¹æ³•ãŒå¤±æ•—ã—ãŸå ´åˆã€åŸºæœ¬çš„ãªéŸ³å£°ã‚’ç”Ÿæˆ
        logger.warning("âš ï¸ ã™ã¹ã¦ã®éŸ³å£°ç”Ÿæˆæ–¹æ³•ãŒå¤±æ•—ã€åŸºæœ¬éŸ³å£°ã‚’ç”Ÿæˆ")
        return await self._generate_basic_audio(shanghai_text)
    
    async def _generate_with_say(self, text: str) -> np.ndarray:
        """macOSã®sayã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ç”¨ï¼ˆä¸­å›½èªå¯¾å¿œç‰ˆï¼‰"""
        try:
            with tempfile.NamedTemporaryFile(suffix='.aiff', delete=False) as f:
                temp_file = f.name
            
            # åˆ©ç”¨å¯èƒ½ãªä¸­å›½èªéŸ³å£°ã‚’ç¢ºèª
            cmd_check = ['say', '-v', '?']
            result_check = subprocess.run(cmd_check, capture_output=True, text=True, timeout=5)
            
            # ä¸­å›½èªéŸ³å£°ã‚’é¸æŠï¼ˆåˆ©ç”¨å¯èƒ½ãªã‚‚ã®ã‹ã‚‰ï¼‰
            chinese_voices = ['Ting-Ting', 'Sin-ji', 'Mei-Jia', 'Yu-shu']
            selected_voice = 'Ting-Ting'  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            
            if result_check.returncode == 0:
                available_voices = result_check.stdout
                for voice in chinese_voices:
                    if voice in available_voices:
                        selected_voice = voice
                        break
            
            logger.info(f"ä½¿ç”¨ã™ã‚‹ä¸­å›½èªéŸ³å£°: {selected_voice}")
            
            # ä¸­å›½èªãƒ†ã‚­ã‚¹ãƒˆã‚’è‹±èªã«å¤‰æ›ã—ã¦ãƒ†ã‚¹ãƒˆ
            # å®Ÿéš›ã®ä¸­å›½èªéŸ³å£°ç”Ÿæˆã‚’è©¦è¡Œ
            cmd = [
                'say', 
                '-v', selected_voice,  # ä¸­å›½èªéŸ³å£°
                '-r', '100',           # è©±é€Ÿã‚’é…ã
                '-o', temp_file, 
                text
            ]
            
            logger.info(f"sayã‚³ãƒãƒ³ãƒ‰å®Ÿè¡Œ: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=15)
            
            if result.returncode != 0:
                logger.warning(f"say ã‚³ãƒãƒ³ãƒ‰å¤±æ•—: {result.stderr}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: è‹±èªéŸ³å£°ã§ä¸­å›½èªã‚’èª­ã¿ä¸Šã’
                english_text = "Hello, this is a Chinese dialect pronunciation test."
                cmd_fallback = [
                    'say', 
                    '-v', 'Alex',  # è‹±èªéŸ³å£°
                    '-r', '120',
                    '-o', temp_file, 
                    english_text
                ]
                logger.info(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ: {' '.join(cmd_fallback)}")
                result = subprocess.run(cmd_fallback, capture_output=True, text=True, timeout=15)
                if result.returncode != 0:
                    raise Exception(f"say fallback failed: {result.stderr}")
            
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            if not os.path.exists(temp_file) or os.path.getsize(temp_file) == 0:
                raise Exception("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒç”Ÿæˆã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            
            audio, sr = librosa.load(temp_file, sr=self.sample_rate)
            os.unlink(temp_file)
            
            # éŸ³å£°ãŒçŸ­ã™ãã‚‹å ´åˆã¯è­¦å‘Š
            if len(audio) < 1000:  # 0.05ç§’æœªæº€
                logger.warning(f"ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãŒçŸ­ã™ãã¾ã™: {len(audio)} samples, {len(audio)/self.sample_rate:.2f}s")
                return None
            
            logger.info(f"sayéŸ³å£°ç”ŸæˆæˆåŠŸ: {len(audio)} samples, {len(audio)/self.sample_rate:.2f}s")
            return audio
            
        except Exception as e:
            logger.warning(f"say ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    async def _generate_with_espeak(self, text: str) -> np.ndarray:
        """espeakã‚’ä½¿ç”¨"""
        try:
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
                temp_file = f.name
            
            # espeakã§éŸ³å£°ç”Ÿæˆ
            cmd = ['espeak', '-v', 'zh', '-s', '150', '-w', temp_file, text]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
            
            if result.returncode != 0:
                raise Exception(f"espeak failed: {result.stderr}")
            
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            audio, sr = librosa.load(temp_file, sr=self.sample_rate)
            os.unlink(temp_file)
            
            return audio
            
        except Exception as e:
            logger.warning(f"espeak ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    async def _generate_with_python_tts(self, text: str) -> np.ndarray:
        """Python TTSãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ï¼ˆæ”¹è‰¯ç‰ˆï¼‰"""
        try:
            import pyttsx3
            
            engine = pyttsx3.init()
            
            # åˆ©ç”¨å¯èƒ½ãªéŸ³å£°ã‚’ç¢ºèª
            voices = engine.getProperty('voices')
            chinese_voice = None
            
            # ä¸­å›½èªéŸ³å£°ã‚’æ¢ã™
            for voice in voices:
                if 'chinese' in voice.name.lower() or 'mandarin' in voice.name.lower() or 'zh' in voice.id.lower():
                    chinese_voice = voice
                    break
            
            if chinese_voice:
                engine.setProperty('voice', chinese_voice.id)
                logger.info(f"ä½¿ç”¨ã™ã‚‹Python TTSéŸ³å£°: {chinese_voice.name}")
            else:
                logger.info("ä¸­å›½èªéŸ³å£°ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆéŸ³å£°ã‚’ä½¿ç”¨")
            
            # éŸ³å£°è¨­å®š
            engine.setProperty('rate', 120)      # è©±é€Ÿã‚’å°‘ã—é…ã
            engine.setProperty('volume', 0.9)    # éŸ³é‡ã‚’ä¸Šã’ã‚‹
            
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as f:
                temp_file = f.name
            
            engine.save_to_file(text, temp_file)
            engine.runAndWait()
            
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            audio, sr = librosa.load(temp_file, sr=self.sample_rate)
            os.unlink(temp_file)
            
            logger.info(f"Python TTSéŸ³å£°ç”ŸæˆæˆåŠŸ: {len(audio)} samples, {len(audio)/self.sample_rate:.2f}s")
            return audio
            
        except Exception as e:
            logger.warning(f"Python TTS ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    async def _generate_with_basic_synthesis(self, text: str) -> np.ndarray:
        """åŸºæœ¬çš„ãªéŸ³å£°åˆæˆ"""
        try:
            # æ–‡å­—æ•°ã«å¿œã˜ã¦éŸ³å£°ã®é•·ã•ã‚’æ±ºå®š
            duration = max(1.0, len(text) * 0.5)  # æœ€ä½1ç§’ã€æ–‡å­—æ•°Ã—0.5ç§’
            t = np.linspace(0, duration, int(self.sample_rate * duration))
            
            # è¤‡æ•°ã®å‘¨æ³¢æ•°ã§éŸ³å£°ã‚’ç”Ÿæˆ
            base_freq = 220  # A3
            frequencies = [base_freq, base_freq * 1.5, base_freq * 2, base_freq * 3]
            audio = np.zeros_like(t)
            
            # å„æ–‡å­—ã«å¯¾å¿œã™ã‚‹éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
            char_duration = duration / len(text)
            
            for i, char in enumerate(text):
                if char.strip():  # ç©ºç™½æ–‡å­—ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    start_time = i * char_duration
                    end_time = (i + 1) * char_duration
                    
                    # æ™‚é–“ç¯„å›²ã‚’è¨ˆç®—
                    start_idx = int(start_time * self.sample_rate)
                    end_idx = int(end_time * self.sample_rate)
                    
                    if start_idx < len(t) and end_idx <= len(t):
                        segment_t = t[start_idx:end_idx]
                        
                        # æ–‡å­—ã«å¿œã˜ã¦å‘¨æ³¢æ•°ã‚’é¸æŠ
                        freq = frequencies[i % len(frequencies)]
                        
                        # éŸ³å£°æ³¢å½¢ã‚’ç”Ÿæˆ
                        fundamental = np.sin(2 * np.pi * freq * segment_t)
                        harmonic2 = 0.3 * np.sin(2 * np.pi * freq * 2 * segment_t)
                        harmonic3 = 0.1 * np.sin(2 * np.pi * freq * 3 * segment_t)
                        
                        segment_audio = fundamental + harmonic2 + harmonic3
                        
                        # ã‚¨ãƒ³ãƒ™ãƒ­ãƒ¼ãƒ—ã‚’é©ç”¨
                        envelope = np.exp(-segment_t * 1.0) * (1 + 0.1 * np.sin(2 * np.pi * 3 * segment_t))
                        segment_audio *= envelope
                        
                        # éŸ³é‡ã‚’èª¿æ•´
                        segment_audio *= 0.2
                        
                        audio[start_idx:end_idx] += segment_audio
            
            # æ­£è¦åŒ–
            if np.max(np.abs(audio)) > 0:
                audio = audio / np.max(np.abs(audio)) * 0.5
            
            return audio
            
        except Exception as e:
            logger.error(f"åŸºæœ¬éŸ³å£°åˆæˆã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    async def _generate_basic_audio(self, text: str) -> np.ndarray:
        """åŸºæœ¬çš„ãªéŸ³å£°ç”Ÿæˆï¼ˆæœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        logger.info("ğŸ”„ åŸºæœ¬éŸ³å£°ç”Ÿæˆã‚’ä½¿ç”¨")
        
        # ã‚·ãƒ³ãƒ—ãƒ«ãªéŸ³å£°ã‚’ç”Ÿæˆ
        duration = max(2.0, len(text) * 0.3)  # æœ€ä½2ç§’
        t = np.linspace(0, duration, int(self.sample_rate * duration))
        
        # åŸºæœ¬çš„ãªã‚µã‚¤ãƒ³æ³¢
        freq = 220  # A3
        audio = 0.3 * np.sin(2 * np.pi * freq * t)
        
        # ã‚¨ãƒ³ãƒ™ãƒ­ãƒ¼ãƒ—ã‚’é©ç”¨
        envelope = np.exp(-t * 0.5)
        audio *= envelope
        
        return audio
    
    def get_audio_info(self, audio: np.ndarray) -> Dict[str, Any]:
        """éŸ³å£°æƒ…å ±ã‚’å–å¾—"""
        duration = len(audio) / self.sample_rate
        rms = np.sqrt(np.mean(audio**2))
        peak = np.max(np.abs(audio))
        
        # ãƒ‰ãƒŸãƒŠãƒ³ãƒˆå‘¨æ³¢æ•°ã‚’è¨ˆç®—
        fft = np.fft.fft(audio)
        freqs = np.fft.fftfreq(len(audio), 1/self.sample_rate)
        dominant_freq = freqs[np.argmax(np.abs(fft))]
        
        return {
            'duration': duration,
            'sample_rate': self.sample_rate,
            'rms': float(rms),
            'peak': float(peak),
            'dominant_frequency': float(abs(dominant_freq)),
            'length_samples': len(audio)
        }

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
simple_voice_generator = SimpleVoiceGenerator()

async def generate_voice(text: str) -> np.ndarray:
    """éŸ³å£°ã‚’ç”Ÿæˆï¼ˆå¤–éƒ¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰"""
    return await simple_voice_generator.generate_voice(text)

def get_audio_info(audio: np.ndarray) -> Dict[str, Any]:
    """éŸ³å£°æƒ…å ±ã‚’å–å¾—ï¼ˆå¤–éƒ¨ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰"""
    return simple_voice_generator.get_audio_info(audio)

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆ
    async def test():
        text = "ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”å¾ˆå¥½ã€‚"
        audio = await generate_voice(text)
        info = get_audio_info(audio)
        print(f"éŸ³å£°æƒ…å ±: {info}")
        
        # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
        sf.write("test_simple.wav", audio, 22050)
        print("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜: test_simple.wav")
    
    asyncio.run(test())
